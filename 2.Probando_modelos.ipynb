{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Output/dataset_limpio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [a for a in data.columns if a not in [\"price\"]]\n",
    "X = data[columnas]\n",
    "y = data[\"price\"]\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>62.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.70</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.80</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.85</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>61.8</td>\n",
       "      <td>59.2</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.13</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>0.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>61.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.72</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>0.30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.64</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.12</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.98</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>2.02</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>62.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.97</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.99</td>\n",
       "      <td>15064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  cut  color  clarity  depth  table     x     y     z  price\n",
       "0       0.30    4      2        5   62.8   56.0  4.29  4.31  2.70    605\n",
       "1       0.34    2      1        2   62.6   55.0  4.46  4.49  2.80    565\n",
       "2       0.40    4      0        2   60.3   62.0  4.70  4.75  2.85    720\n",
       "3       0.40    3      4        4   61.8   59.2  4.72  4.74  2.92    793\n",
       "4       0.90    4      0        2   61.0   63.0  6.10  6.13  3.73   4381\n",
       "...      ...  ...    ...      ...    ...    ...   ...   ...   ...    ...\n",
       "40450   0.32    2      0        4   61.5   56.0  4.41  4.43  2.72    862\n",
       "40451   0.30    2      0        5   60.9   57.0  4.32  4.35  2.64    710\n",
       "40452   0.47    3      3        2   62.7   58.0  4.97  4.99  3.12    931\n",
       "40453   0.40    1      3        5   63.5   56.0  4.68  4.70  2.98    807\n",
       "40454   2.02    4      4        3   62.3   58.0  7.97  8.04  4.99  15064\n",
       "\n",
       "[40455 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop([\"x\",\"y\",\"z\"], axis=1) \n",
    "#data = data.drop([\"table\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos modelos de regression para hacer el test\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\" : RandomForestRegressor(),\n",
    "    \"Logistic regression\": TweedieRegressor(power=1, alpha=0.5, link='log'),\n",
    "    \"KNeigbhors\": KNeighborsRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Decision Tree\":tree.DecisionTreeRegressor(),\n",
    "    \"Tree\" : DecisionTreeRegressor(),\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"Bagging Regressor\": BaggingRegressor(random_state=0),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest\n",
      "Training Logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeigbhors\n",
      "Training SVR\n",
      "Training Decision Tree\n",
      "Training Tree\n",
      "Training AdaBoost\n",
      "Training Bagging Regressor\n",
      "Training Gradient Boosting\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos los modelos\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}\")\n",
    "    model.fit(X_train,y_train)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------RandomForest-------\n",
      "r2 score 0.9804\n",
      "RMSE: 555.0 4\n",
      "-------Logistic regression-------\n",
      "r2 score 0.8522\n",
      "RMSE: 1526.0 4\n",
      "-------KNeigbhors-------\n",
      "r2 score 0.9426\n",
      "RMSE: 951.0 4\n",
      "-------SVR-------\n",
      "r2 score -0.138\n",
      "RMSE: 4234.0 4\n",
      "-------Decision Tree-------\n",
      "r2 score 0.9603\n",
      "RMSE: 790.0 4\n",
      "-------Tree-------\n",
      "r2 score 0.9628\n",
      "RMSE: 765.0 4\n",
      "-------AdaBoost-------\n",
      "r2 score 0.8905\n",
      "RMSE: 1313.0 4\n",
      "-------Bagging Regressor-------\n",
      "r2 score 0.978\n",
      "RMSE: 588.0 4\n",
      "-------Gradient Boosting-------\n",
      "r2 score 0.9724\n",
      "RMSE: 660.0 4\n"
     ]
    }
   ],
   "source": [
    "# Analizamos su R2 y RMSE para ver con quÃ© modelos nos quedamos\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"-------{name}-------\")\n",
    "    print(\"r2 score\",round(r2_score(y_test, y_pred),4))\n",
    "    print('RMSE:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred))),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testeamos columnas para ver si mejora el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probamos dropeando columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = [\n",
    "    StandardScaler(),\n",
    "    #Normalizer(),\n",
    "    ]\n",
    "\n",
    "tr = make_pipeline(*pipeline)\n",
    "\n",
    "Xpr = tr.fit_transform(data)\n",
    "Xpr = pd.DataFrame(Xpr,columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------RandomForest-------\n",
      "r2 score 0.9929\n",
      "RMSE: 329.0 4\n",
      "-------Logistic regression-------\n",
      "r2 score 0.8613\n",
      "RMSE: 1456.0 4\n",
      "-------KNeigbhors-------\n",
      "r2 score 0.9562\n",
      "RMSE: 818.0 4\n",
      "-------SVR-------\n",
      "r2 score -0.1227\n",
      "RMSE: 4144.0 4\n",
      "-------Decision Tree-------\n",
      "r2 score 0.9907\n",
      "RMSE: 378.0 4\n",
      "-------Tree-------\n",
      "r2 score 0.9906\n",
      "RMSE: 379.0 4\n",
      "-------AdaBoost-------\n",
      "r2 score 0.887\n",
      "RMSE: 1315.0 4\n",
      "-------Bagging Regressor-------\n",
      "r2 score 0.9915\n",
      "RMSE: 360.0 4\n",
      "-------Gradient Boosting-------\n",
      "r2 score 0.9728\n",
      "RMSE: 645.0 4\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"-------{name}-------\")\n",
    "    print(\"r2 score\",round(r2_score(y_test, y_pred),4))\n",
    "    print('RMSE:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred))),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.091669</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.990348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.109601</td>\n",
       "      <td>0.096295</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.989212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.083146</td>\n",
       "      <td>0.085491</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.992794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.077476</td>\n",
       "      <td>0.074217</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.994153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.999797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.071013</td>\n",
       "      <td>0.064662</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.995333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006994</td>\n",
       "      <td>0.085183</td>\n",
       "      <td>0.079728</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.993098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.067062</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.995772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.078252</td>\n",
       "      <td>0.069009</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.994475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat       cut     color   clarity     depth     table         x  \\\n",
       "0      0.000491  0.006548  0.003274  0.008185  0.102800  0.091669  0.007022   \n",
       "1      0.000595  0.003502  0.001751  0.003502  0.109601  0.096295  0.007809   \n",
       "2      0.000552  0.005516  0.000000  0.002758  0.083146  0.085491  0.006481   \n",
       "3      0.000501  0.003761  0.005015  0.005015  0.077476  0.074217  0.005917   \n",
       "4      0.000205  0.000913  0.000000  0.000456  0.013921  0.014377  0.001392   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "40450  0.000369  0.002309  0.000000  0.004619  0.071013  0.064662  0.005092   \n",
       "40451  0.000420  0.002797  0.000000  0.006994  0.085183  0.079728  0.006043   \n",
       "40452  0.000503  0.003209  0.003209  0.002139  0.067062  0.062035  0.005316   \n",
       "40453  0.000493  0.001232  0.003697  0.006162  0.078252  0.069009  0.005767   \n",
       "40454  0.000134  0.000266  0.000266  0.000199  0.004136  0.003850  0.000529   \n",
       "\n",
       "              y         z     price  \n",
       "0      0.007055  0.004420  0.990348  \n",
       "1      0.007861  0.004902  0.989212  \n",
       "2      0.006550  0.003930  0.992794  \n",
       "3      0.005942  0.003661  0.994153  \n",
       "4      0.001399  0.000851  0.999797  \n",
       "...         ...       ...       ...  \n",
       "40450  0.005115  0.003141  0.995333  \n",
       "40451  0.006084  0.003693  0.993098  \n",
       "40452  0.005337  0.003337  0.995772  \n",
       "40453  0.005792  0.003672  0.994475  \n",
       "40454  0.000534  0.000331  0.999984  \n",
       "\n",
       "[40455 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [\n",
    "    Normalizer(),\n",
    "    ]\n",
    "\n",
    "tr = make_pipeline(*pipeline)\n",
    "\n",
    "Xpr = tr.fit_transform(data)\n",
    "Xpr = pd.DataFrame(Xpr,columns=data.columns)\n",
    "Xpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [a for a in Xpr.columns if a not in [\"price\"]]\n",
    "X = Xpr[columnas]\n",
    "y = Xpr[\"price\"]\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------RandomForest-------\n",
      "r2 score -66960593274.1019\n",
      "RMSE: 1095.0 4\n",
      "-------Logistic regression-------\n",
      "r2 score -689962566249.5878\n",
      "RMSE: 3513.0 4\n",
      "-------KNeigbhors-------\n",
      "r2 score -495719218077.8435\n",
      "RMSE: 2978.0 4\n",
      "-------SVR-------\n",
      "r2 score -293756356201.7928\n",
      "RMSE: 2292.0 4\n",
      "-------Decision Tree-------\n",
      "r2 score -253359979125.2834\n",
      "RMSE: 2129.0 4\n",
      "-------Tree-------\n",
      "r2 score -253359979125.2834\n",
      "RMSE: 2129.0 4\n",
      "-------AdaBoost-------\n",
      "r2 score -540997611060.7005\n",
      "RMSE: 3111.0 4\n",
      "-------Bagging Regressor-------\n",
      "r2 score -63399675871.5802\n",
      "RMSE: 1065.0 4\n",
      "-------Gradient Boosting-------\n",
      "r2 score -98230328236.3993\n",
      "RMSE: 1326.0 4\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"-------{name}-------\")\n",
    "    print(\"r2 score\",round(r2_score(y_test, y_pred),4))\n",
    "    print('RMSE:', round(np.sqrt(metrics.mean_squared_error(y_test, y_pred))),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop([\"x\",\"y\",\"z\"], axis=1) \n",
    "#data = data.drop([\"table\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop([\"table\"], axis=1)\n",
    "# baja precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = data.to_csv('Output/modelo_entrenado.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization with GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos para hacer la prueba con diferentes n_estimators\n",
    "params = {\n",
    "     'n_estimators': [200, 300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-22-dc8d799fcc09>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-dc8d799fcc09>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cv = 3, n_jobs = -1, verbose = 2)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the grid search model\n",
    "#grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "#grid_search.fit(X_train,y_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado:regr = bootstrap=True, max_depth= 100,max_features= 3, min_samples_leaf=3,min_samples_split=8,n_estimators=1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "#standard scaler--> https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
